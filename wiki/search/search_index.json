{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"index.html","title":"Home","text":"<p>Welcome to the HyperHDR wiki!  </p> <p>I'd suggest starting with a list of the hardware components: needed components Also you may want to visit the software installation manual and finally go through the quick start guide</p>"},{"location":"Audio-reactive.html","title":"Audio-reactive lighting effects","text":"<p>One of HyperHDR\u2019s unique features is visualization based on sound amplitude and frequency in your ambient ecosystem using a USB grabber. PCM digital capture devices are preferred, as there is no analog sound filter available at the input in the current version. To make it work, you must ensure that the grabber receives an PCM audio stream. Be aware that some amplifiers, like Denon, may block it in a typical configuration (using ARC/eARC is necessary in that case).</p> <p>Let's configure the hardware first in the 'Effect' tab. On the following screen I selected Ezcap 269 device. Do not confuse it with some other system devices. </p> <p>Next we need to enable 'Activate' option and save our settings. </p> <p>Navigate to the 'Remote control' tab and turn on video preview to verify result. </p> <p>For the beginning use 'Equalizer' from the list to test if everything works OK. </p> <p>If you activated &amp; set up your grabber correctly and it receives a audio stream you should see jumping equalizer's bars.  </p> <p>If the bars are standing still flat, something is wrong. It almost always means that your grabber is not receiving sound or the driver is unable to handle the given format (e.g. Dolby Audio instead of PCM) or the capture frequency (22kHz). Using the 'Equalizer' audio effect go to the 'Logs' tab to confirm this...  </p> <p></p> <p>It\u2019s a final confirmation: you have enabled an audio device and it works, but it provides no sound\u2026 only silence. Maybe you selected the wrong device, but more likely there is no audio on the grabber\u2019s input (e.g. the amplifier blocked it) or there is an issue with the audio format.</p>"},{"location":"Automatic-tone-mapping.html","title":"Automatic tone mapping","text":"<p>HyperHDR v21 introduced the feature of automatically enabling/disabling tone mapping depending on whether we are dealing with an SDR or HDR signal. It takes advantage of the fact that the captured raw HDR image is much darker and washed out than the SDR signal.</p>"},{"location":"Automatic-tone-mapping.html#preparations","title":"Preparations","text":"<ul> <li>Currently, the automatic tone mapping function only supports YUV/NV12/P010 codecs. It is possible that this list will be expanded in the future.</li> <li>The <code>Quarter of frame mode</code> option must be enabled in the grabber settings. This also limits the processor load, because the entire video frame is analyzed.</li> </ul>"},{"location":"Automatic-tone-mapping.html#hyperhdr-configuration","title":"HyperHDR configuration","text":"<p>Select the \"Image Processing\" tab and scroll the page down.</p> <p>In the configuration panel you can activate the automatic tone mapping function and also define the sensitivity thresholds for brightness (Y) and two components defining color (U, V) in range 0-255. The screenshot shows the default settings that should work for most grabbers. If you are using this feature only for movies, you can even try lowering the brightness threshold to 155. Setting the threshold too high can cause unwanted tone mapping in dark SDR scenes.</p> <p>If the tone mapping off appears in unwanted circumstances when HDR material is played, it may mean that one of the thresholds is set too low. If this happens, open the HyperHDR logs and you will find there the value that exceeded one of the thresholds and based on it you can correct the configuration.</p> <p> </p>"},{"location":"Automatic-tone-mapping.html#diagnostic","title":"Diagnostic","text":"<p>Here's an example of a very bright SDR signal (that replaced a previous HDR video) causing tone mapping to be disabled:</p> <p></p> <p>Later the HDR signal appears again and since it did not cause the thresholds to be exceeded for 30 seconds, tone mapping was automatically enabled.</p> <p></p>"},{"location":"Common-problems-%26-questions.html","title":"Common problems & questions","text":"<p>LED strip flickering in random area</p> <p>How can i install HyperHDR under Libreelec?</p> <p>What do these HyperHDR performance statistics mean?</p> <p>Alternative ARM platforms for Raspberry pi</p>"},{"location":"Compiling-HyperHDR.html","title":"Available methods to build HyperHDR:","text":""},{"location":"Compiling-HyperHDR.html#1-native-build","title":"1. Native build","text":""},{"location":"Compiling-HyperHDR.html#2-build-a-hyperhdr-installer-for-any-supported-linux-system-on-any-system-using-docker","title":"2. Build a HyperHDR installer for any supported Linux system on any system using Docker","text":""},{"location":"Compiling-HyperHDR.html#3-online-github-action","title":"3. Online: Github Action","text":""},{"location":"Compiling-HyperHDR.html#native-build","title":"Native build","text":""},{"location":"Compiling-HyperHDR.html#preparing-build-environment","title":"Preparing build environment","text":""},{"location":"Compiling-HyperHDR.html#debianubuntu","title":"Debian/Ubuntu","text":"<pre><code>sudo apt-get update\n\nsudo apt-get install build-essential cmake flatbuffers-compiler git libasound2-dev libayatana-appindicator3-dev libegl-dev libflatbuffers-dev libftdi1-dev libgl-dev libglvnd-dev libgtk-3-dev liblzma-dev libpipewire-0.3-dev libssl-dev libsystemd-dev libturbojpeg0-dev libusb-1.0-0-dev libx11-dev libzstd-dev ninja-build patchelf pkg-config python3 qt6-serialport-dev qt6-base-dev unzip wget chrpath\n</code></pre> <p>For Raspberry Pi CEC support (optional) <pre><code>sudo apt-get install libcec-dev libp8-platform-dev libudev-dev\n</code></pre></p>"},{"location":"Compiling-HyperHDR.html#fedora","title":"Fedora","text":"<pre><code>sudo dnf -y install alsa-lib-devel chrpath cmake fedora-packager flatbuffers-compiler flatbuffers-devel gcc gcc-c++ git gtk3-devel libX11-devel libayatana-appindicator-gtk3-devel libftdi-c++-devel libglvnd-devel libusb1-devel libzstd-devel mesa-libEGL-devel mesa-libGL-devel ninja-build openssl-devel pipewire-devel pkg-config qt6-qtbase-devel qt6-qtserialport-devel systemd-devel turbojpeg-devel unzip wget xz-devel chrpath\n</code></pre>"},{"location":"Compiling-HyperHDR.html#arch-linux","title":"Arch Linux","text":"<pre><code>sudo pacman -Syy\n\nsudo pacman -S alsa-lib base-devel bash binutils chrpath cmake dpkg fakeroot flatbuffers freetds git gtk3 libayatana-appindicator libfbclient libftdi libglvnd libjpeg-turbo libx11 mariadb-libs mesa ninja openssl pipewire pkgfile postgresql-libs python qt6-base qt6-serialport sdbus-cpp systemd-libs unzip wayland wget xz chrpath\n</code></pre>"},{"location":"Compiling-HyperHDR.html#windows","title":"Windows","text":"<p>We assume a 64bit Windows 10. Install the following:</p> <ul> <li>Git (Check during installation: Add to PATH)</li> <li>CMake (Windows win64-x64 Installer) (Check during installation: Add to PATH)</li> <li>Visual Studio 2022 Community Edition<ul> <li>Select 'Desktop development with C++'</li> <li>On the right, just select <code>MSVC v143 VS 2022 C++ x64/x86-Buildtools</code> and latest <code>Windows 10 SDK</code>. Everything else is not needed, but you can stay with default selection.</li> </ul> </li> <li>OpenSSL (for QT5.15-6.2: OpenSSL v1.1.1, for QT6: OpenSSL 3)</li> <li>libjpeg-turbo</li> <li>Python 3 (Windows x86-64 executable installer) (Check during installation: Add to PATH and Debug Symbols)<ul> <li>Open a console window and execute <code>pip install aqtinstall</code>.</li> <li>Now we can download Qt to C:\\Qt <code>mkdir c:\\Qt &amp;&amp; aqt install -O c:\\Qt 6.8.3 windows desktop win64_msvc2022_64 -m qtserialport</code></li> <li>May need to add QT6 path before compiling, for example: <code>set CMAKE_PREFIX_PATH=C:\\Qt\\6.8.3\\msvc2022_64\\lib\\cmake\\</code> or for older QT5 <code>set Qt5_Dir=C:\\Qt\\5.15.2\\msvc2019_64\\lib\\cmake\\Qt5\\</code></li> </ul> </li> <li>Optional for creating installer packages: NSIS 3.x (direct link)</li> </ul> <p>Tip</p> <p>After you execute the configuration command in the build folder (for example <code>cmake -DCMAKE_BUILD_TYPE=Release ..</code>) you should receive *.sln solution project file that can be opened in Visual Studio. Select <code>hyperhdr</code> project as default for the solution to run it after compilation.</p>"},{"location":"Compiling-HyperHDR.html#macos","title":"macOS","text":"<p>First install brew manager. Next: <code>brew install qtbase qtserialport cmake xz pkg-config</code></p>"},{"location":"Compiling-HyperHDR.html#compiling-and-installing-hyperhdr","title":"Compiling and installing HyperHDR","text":""},{"location":"Compiling-HyperHDR.html#linuxmacos-the-general-quick--recommended-way","title":"Linux/macOS: the general quick &amp; recommended way","text":"<pre><code>git clone --recursive https://github.com/awawa-dev/HyperHDR.git hyperhdr\ncd hyperhdr\nmkdir build\ncd build\ncmake -DCMAKE_BUILD_TYPE=Release ..\nmake -j $(nproc)\n\n# if this get stucked and dmesg says out of memory try:\nmake -j 2\n\n# Run it from the build directory\nbin/hyperhdr -d\n\n# BUILD INSTALLERS (recommended method to install HyperHDR, doesnt work for ArchLinux: use build.sh script )\ncpack\n# or compile and build the package using one command\ncmake --build . --target package --config Release\n</code></pre>"},{"location":"Compiling-HyperHDR.html#windows-the-general-quick--recommended-way","title":"Windows: the general quick &amp; recommended way","text":"<pre><code>git clone --recursive https://github.com/awawa-dev/HyperHDR.git hyperhdr\ncd hyperhdr\nmkdir build\ncd build\n# You might need to setup MSVC env first\ncall \"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Auxiliary\\Build\\vcvars64.bat\"\n# Maintainers: to build the HyperHDR installer, install NSIS and define environment variable:  \n# set VCINSTALLDIR=\"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\"\ncmake -DPLATFORM=windows -G \"Visual Studio 17 2022\" -DCMAKE_BUILD_TYPE=Release ..\ncmake --build . --config Release -- -maxcpucount\n\n# Run it from the build directory\nbin/Release/hyperhdr -d\n</code></pre>"},{"location":"Compiling-HyperHDR.html#libreelec","title":"LibreELEC","text":"<p>You can find the add-on sources here on branches of my LibreELEC fork: link For example <code>libreelec-11.0-hyperhdr</code> branch. Adjust HyperHDR package properties in <code>packages/addons/service/hyperhdr/package.mk</code> Follow LibreELEC's manual on how to build the image. For example: </p> <p>LibreELEC 11/RPi: <pre><code>PROJECT=RPi ARCH=arm DEVICE=RPi4 make image\nPROJECT=RPi DEVICE=RPi4 ARCH=arm ./scripts/create_addon hyperhdr\n</code></pre></p> <p>LibreELEC 12/RPi: <pre><code>PROJECT=RPi ARCH=aarch64 DEVICE=RPi4 make image\nPROJECT=RPi DEVICE=RPi4 ARCH=aarch64 ./scripts/create_addon hyperhdr\n</code></pre></p> <p>PC(x86_64): <pre><code>PROJECT=Generic ARCH=x86_64 DEVICE=Generic make image\nPROJECT=Generic DEVICE=Generic ARCH=x86_64 ./scripts/create_addon hyperhdr\n</code></pre></p>"},{"location":"Compiling-HyperHDR.html#build-a-hyperhdr-installer-for-any-supported-linux-system-on-any-system-using-docker","title":"Build a HyperHDR installer for any supported Linux system on any system using Docker","text":"<p>All you need is Docker and Bash, which are available on every supported system \u2014 even on Windows, where you only need to enable \"Windows Subsystem for Linux\". You don\u2019t need to install any additional packages to build HyperHDR, because the script uses Docker images provided by HyperDockerBuilder, which contain everything required to create the installer. Thanks to this, you can compile, for example, the aarch64 HyperHDR installer for Raspberry Pi directly on a PC. To start, run the <code>build.sh</code> script in the main directory.</p> <pre><code>pi@ubuntu:~/hyperhdr$ ./build.sh \n\nRequired environmental options:\nPLATFORM - one of the supported targets: osx|windows|linux|rpi\nDISTRO_NAME  | DISTRO_VERSION | ARCHITECTURE - these are only for linux targets\n   debian    | bullseye       | armhf\n   debian    | bullseye       | arm64\n   debian    | bullseye       | amd64\n   debian    | bookworm       | armhf\n   debian    | bookworm       | arm64\n   debian    | bookworm       | amd64\n   debian    | trixie         | armhf\n   debian    | trixie         | arm64\n   debian    | trixie         | amd64\n   ubuntu    | jammy          | amd64\n   ubuntu    | noble          | amd64\n   ubuntu    | questing       | amd64\n   fedora    | 43             | amd64\n   archlinux | latest         | amd64\n\nOptional environmental options:\nBUILD_TYPE - Release|Debug, default is Release version\nBUILD_ARCHIVES - false|true, cpack will build ZIP package\nUSE_STANDARD_INSTALLER_NAME - false|true, use standard Linux package naming\nUSE_CCACHE - false|true, use ccache if available\nRESET_CACHE - false|true, reset ccache storage\n\nExample of usage:\nPLATFORM=rpi DISTRO_NAME=debian DISTRO_VERSION=bullseye ARCHITECTURE=arm64 ./build.sh\nInstallers from Docker builds will be ready in the deploy folder\n</code></pre> <p>The <code>build.sh</code> script can also be used to natively build macOS/Windows installers as an alternative to the method described in the previous point. Of course, then you must have all the necessary packages installed.</p>"},{"location":"Compiling-HyperHDR.html#onlinegithub-action","title":"Online:Github Action","text":"<p>Fork HyperHDR project. Now you must enable project's <code>Settings \u2192 Actions \u2192 Actions permissions \u2192 Allow all actions and reusable workflows</code> and save it. Once you've done this, any change, even using the Github online editor, will immediately trigger the build in the Actions tab. If this did not happen, you probably did not enable the option described or did it later after making the changes.</p>"},{"location":"Compiling-HyperHDR.html#available-cmake-hyperhdr-configuration-options","title":"Available CMake HyperHDR configuration options:","text":"<p>Use -D prefix when configuring the build.</p> <ul> <li> <p>LED DEVICES  </p> <ul> <li>ENABLE_SPIDEV = ON | OFF, enables SPI LED devices on supported systems</li> <li>ENABLE_SPI_FTDI = ON | OFF, enables SPI libFTDI (FTDI for Windows) controller</li> <li>ENABLE_WS281XPWM = ON | OFF, enables WS281x LED library for RPi 1-4</li> </ul> </li> <li> <p>SOFTWARE GRABBERS</p> <ul> <li>ENABLE_DX = ON | OFF, enables the DirectX11 software grabber (Windows)</li> <li>ENABLE_FRAMEBUFFER = ON | OFF, enables the Framebuffer software grabber (Linux)</li> <li>ENABLE_MAC_SYSTEM = ON | OFF, enables the macOS software grabber (macOS)</li> <li>ENABLE_PIPEWIRE = ON | OFF, enables the Pipewire software grabber (Linux)</li> <li>ENABLE_PIPEWIRE_EGL = ON | OFF, enables EGL for the Pipewire grabber (Linux)</li> <li>ENABLE_X11 = ON | OFF, enables the X11 software grabber (Linux)</li> <li>ENABLE_AMLOGIC = ON | OFF, forces the Amlogic software grabber (Linux)</li> </ul> </li> <li> <p>HARDWARE GRABBERS</p> <ul> <li>ENABLE_AVF = ON | OFF, enables the AVF USB grabber support (macOS)</li> <li>ENABLE_MF = ON | OFF, enables the MediaFoundation USB grabber support (Windows)</li> <li>ENABLE_V4L2 = ON | OFF, enables the V4L2 USB grabber support (Linux)</li> </ul> </li> <li> <p>SOUND CAPTURING</p> <ul> <li>ENABLE_SOUNDCAPLINUX = ON | OFF, enables the ALSA sound grabber (Linux)</li> <li>ENABLE_SOUNDCAPMACOS = ON | OFF, enables the sound grabber (macOS)</li> <li>ENABLE_SOUNDCAPWINDOWS = ON | OFF, enables the sound grabber (Windows)</li> </ul> </li> <li> <p>SERVICE SUPPORT</p> <ul> <li>ENABLE_BONJOUR = ON | OFF, enables mDNS (do not disable unless required)</li> <li>ENABLE_CEC = ON | OFF, enables the HDMI-CEC support (Linux)</li> <li>ENABLE_MQTT = ON | OFF, enables the MQTT support</li> <li>ENABLE_POWER_MANAGEMENT = ON | OFF, enables sleep/wake up OS events support</li> <li>ENABLE_PROTOBUF = ON | OFF, enables Proto-Buffer server</li> <li>ENABLE_SYSTRAY = ON | OFF, enables the systray-widget</li> <li>ENABLE_ZSTD = ON | OFF, enables ZSTD support for LUT decompression</li> </ul> </li> <li> <p>BUILD FEATURES</p> <ul> <li>USE_SHARED_LIBS = ON | OFF, build the application as non-monolithic</li> <li>USE_EMBEDDED_WEB_RESOURCES = ON | OFF, embed web content into the app</li> <li>USE_PRECOMPILED_HEADERS = ON | OFF, use pre-compiled headers when building</li> <li>USE_CCACHE_CACHING = ON | OFF, enable CCache support if available</li> <li>USE_SYSTEM_MQTT_LIBS = ON | OFF, prefer system qMQTT libs</li> <li>USE_SYSTEM_FLATBUFFERS_LIBS = ON | OFF, prefer system Flatbuffers libs</li> <li>USE_SYSTEM_SDBUS_CPP_LIBS = ON | OFF, prefer system sdbus_c++ libs</li> <li>USE_SYSTEM_LUNASVG_LIBS = ON | OFF, prefer system lunasvg libs</li> <li>USE_SYSTEM_NANOPB_LIBS = ON | OFF, prefer system nanopb libs</li> <li>USE_SYSTEM_STB_LIBS = ON | OFF, prefer system stb libs</li> <li>USE_STATIC_QT_PLUGINS = ON | OFF, embed static QT-plugins into the app</li> <li>USE_STANDARD_INSTALLER_NAME = ON | OFF, use standard Linux package naming</li> </ul> </li> </ul>"},{"location":"FAQ.html","title":"FAQ","text":"<p>Check the performance statistics that are updated every minute in System\u2794Log page. </p> <p>We do not support driving WS281x and especially SK6812 LED strips directly from the Raspberry Pi although it's theoretically possible: link. If you made it and it works, fine, but most of our users weren't so lucky. You should use external ESP8266/ESP32 (preferable with CH340G or CP2104 onboard) or better Pico/rp2040 with built-in or external 3.3V to 5V voltage level shifter.</p> <p>Usage of WS281x/sk6812 LED strip with Rpi directly (PWM mode) requires root privileges. Otherwise you may get 'Error message: mmap() failed' (read more)  The PWM method does not work on Raspberry Pi 5 due to significant hardware board changes! (read more)</p> <p>Incorrect colors using HyperHDR DirectX 11 grabber? <code>Disable automatic manage color for apps</code></p> <p>Example of Docker installation</p> <p>You have a Raspberry Pi 3 or Zero and your USB grabber is producing a video stream with incorrect/inverted/swapped colors?</p> <p>How can i install HyperHDR under Libreelec?</p> <p>Android screen grabber?</p> <p>Amlogic screen grabber (ex. Coreelec) </p> <p>Automatic HDR tone mapping switching for USB grabber using webos/piccap</p> <p>What do these HyperHDR performance statistics mean?</p> <p>Alternative ARM platforms for Raspberry pi But why not try Intel N100 SBC, which offers overwhelmingly higher performance than RPi and affordable Windows 10/11 in which even screen capture works very well using hardware acceleration and stably (currently unachievable under Linux for quite a lot of configurations/distributions, unfortunately)</p> <p>Cannot open '/dev/video0' error code 13, Permission denied</p> <p>Linux Pipewire grabber does not work? First make sure you run HyperHDR as an application (for example: from the menu shortcut) not as a service. </p>"},{"location":"Getting-started.-Needed-components.html","title":"Getting started. Needed components","text":"<p>The following guide summarizes our recommended setups based on our experience and community feedback.  </p> <p>Because no one pays us for continuous hardware testing, and we have no connections with the manufacturers of this equipment and they can change the specifications of a given product at any time we do not provide any guarantee that this set will work without issues in your case. Although it may probably allow you to avoid many costly mistakes with sets that will definitely not work.</p>"},{"location":"Getting-started.-Needed-components.html#-hosting-device","title":"\ud83d\udcbb Hosting device","text":"Platform System Any modern PC with x64 Intel/AMD Windows/Linux Apple computer x64/arm64 (M1-M4) macOS SoC x64: Intel N100 Windows/Linux SoC ARMv8: Raspberry Pi 4/5 (\u22651 GB RAM) Linux <p>The cheapest N100 models may be louder than the RPi 5 with active cooling, but HyperHDR itself won't push the system to that level of load. However, the N100 is significantly faster than the RPi5 in our video processing. Although HyperHDR can run even on the RPi Zero, we definitely recommend and focus exclusively on using at a minimum a Raspberry Pi 4 equipped with the crucial USB 3.0 port.  </p> <p>For Raspberry Pi, use only the original power supply. I have seen too many cases where users got into serious trouble using LED power supplies or cheap phone chargers to power them.</p>"},{"location":"Getting-started.-Needed-components.html#-led-components","title":"\ud83d\udca1 LED Components","text":"Component Recommendation Notes LED Strip <code>SK6812</code> RGBW Cold White version, 5V LED Power Supply <code>MeanWell</code> Avoid no-name or products from AliExpress\u26a0\ufe0f supportive LEDs <code>Philips Hue lamps</code> Use the genuine Hue Bridge in direct Entertainment mode and avoid ZigBee knock-offs or Home Assistant integrations for best experience."},{"location":"Getting-started.-Needed-components.html#-led-controller-usb","title":"\ud83d\udee0\ufe0f LED Controller (USB)","text":"Type Recommended Boards Notes RP2040 With built-in level shifter - Adafruit Feather RP2040 Scorpio- Adafruit ItsyBitsy RP2040- Pimoroni Plasma 2040- Pimoroni Plasma Stick 2040 W Easiest, best stability and integration Generic RP2040 + external level shifter Any RP2040-based board + external 3.3V to 5V level shifter (ex. Adafruit 6066) More wiring required, avoid slow I2C level-shifters <p>Tip</p> <p>The Raspberry Pi 5 similar to RP2040 has a built-in a PIO co-processor and it can be used via GPIO. Support will be officially added in HyperHDR v22 (already available for testing).  Still it operates only at 3.3V.  </p>"},{"location":"Getting-started.-Needed-components.html#-typical-hardware-setup-usb-grabber--external-hdmi-splitter","title":"\ud83d\udfe2 Typical hardware setup: USB grabber + external HDMI splitter","text":"<p>You\u2019ll need a reliable HDMI splitter or matrix. Based on our own experience, the only brand we can recommend is Ezcoo. Especially if you care about any Dolby Vision support (LLDV only).  </p> Type Notes EZ-SP12H2 4K60, HDCP, HDR, LLDV EZ-SP12H21 4K120, HDCP, HDR, LLDV, VRR, CEC <p>You should connect the TV to Ezcoo Output 1 and the grabber to Output 2. Disable the scaler for Output 1 and enable it for Output 2. Make sure the Ezcoo is set to EDID copy mode.</p> <p>Enabling the scaler will allow you to adjust the video stream at its output to match the capabilities of the capture device, including, for example, changing 4K60 to 1080p60 (or 4K120 to 1080p120, if both the scaler and the grabber support it).</p> <p>Compatible grabbers in this setup</p> Category Model Specs / Notes \ud83c\udfc6 High\u2011End <code>UGREEN 25173</code> SDR/HDR, 4K60/1080P240, VRR, P010 codecThe P010 codec makes a huge differenceP010 works only in Windows and Linux with patched kernel \u2699\ufe0f Lower\u2011End <code>MS2130</code> SDR, max 4K30, officially it's an HDMI 1.4b grabberWith a help from HDMI splitter: HDR and limited support for 1080p120Flash our tested firmware. Factory firmware colors may be broken <p>For the Raspberry Pi, we provide a ready-to-use SD card image with a pre-patched kernel (based on Raspberry Pi OS) that supports the grabber\u2019s P010 codec out of box.</p>"},{"location":"Getting-started.-Needed-components.html#-hardware-all-in-one-setup-usb-grabber-with-built-in-splitter-no-hdcp","title":"\ud83d\udfe1 Hardware all-in-one setup: USB Grabber with built-in splitter (no HDCP)","text":"Category Model Specs \ud83c\udfc6 High-End <code>UGREEN 25173</code> SDR/HDR, 4K60/1080P240, VRR, P010 codec \u2699\ufe0f Lower-End <code>MS2131</code> SDR, max 4K30, HDMI 1.4b only <p>Warning</p> <p>Make sure that your source platform allows you to disable HDCP. Due to licensing restrictions, no modern grabber openly supports video capture if the HDMI signal is protected by HDCP. For HDCP support you need an external HDMI splitter/matrix.  </p>"},{"location":"Getting-started.-Needed-components.html#-software-only-grabbers-if-you-dont-want-to-use-a-usb-grabber","title":"\ud83d\udd34 Software only grabbers: if you don\u2019t want to use a USB grabber","text":"Category Platform Description \ud83c\udfc6 High-End Windows DirectX grabber with HDR support:HyperHDR custom implementation using Pixel &amp; Vertex Shaders \u2699\ufe0f Lower\u2011End Linux Supported but Wayland is much less reliable here than Windows10/11Many performance and compatibility issues compared to Windows \u2699\ufe0f Lower\u2011End macOS Core Graphics (CGImage) screen capture <p>Warning</p> <p>Software grabbers can interfere with video players or games, breaking hardware acceleration or reducing performance. HDCP-dependent streaming applications won\u2019t work and will result in a black screen when capturing. Software grabbers are inferior to hardware solutions.</p>"},{"location":"Home-Assistant-lights.html","title":"Home Assistant lights","text":""},{"location":"Home-Assistant-lights.html#home-assistant-configuration","title":"Home Assistant configuration","text":"<p>I assume you've already configured your lights in Home Assistant. The photo below shows Philips Hue lights connected via a ZigBee adapter.</p> <p></p> <p>If the lights work properly in Home Assistant, you need to create one more thing necessary to support them in HyperHDR: <code>Long Lived Access Token</code>. You will find the required option in the Home Assistant user security settings as in the screenshot below. You must copy it immediately when creating and save it.</p> <p></p>"},{"location":"Home-Assistant-lights.html#hyperhdr-configuration","title":"HyperHDR configuration","text":"<p>Open HyperHDR and go to LED Hardware. Select \"Home Assistant\" from the tab and then click the button to launch the configuration wizard.</p> <p></p> <p>By clicking the <code>Select Home Assistant</code> button you can see the list of instances that HyperHDR has found and choose the one you are interested in. Then below you need to enter the <code>Long Lived Access Token</code> that you created earlier in Home Assistant. When finished click the <code>Continue</code> button.</p> <p></p> <p>On the next page HyperHDR will display all the supported lights it found in the Home Assistant instance. Now you can assign them a default position to the screen and intuit each of them (it will be turned off and on) so you can see which lamp you are configuring. You can always fix this configuration later in the LED layout editor. When you are done, save your changes.</p> <p></p> <p>Congratulations! That's all. In the options you can also:</p> <ul> <li> <p>choose between the RGB or HSL model. Each of them behaves slightly differently and it also depends on the lamp model how/whether it supports it or not</p> </li> <li> <p>set <code>transition time</code> which will provide smoother color transitions at the expense of delay</p> </li> <li> <p>by default <code>brightness</code> is not dynamic and not depends on the brightness of the selected color. However, you can change it and force it to be dynamic.  </p> </li> </ul> <p>Caution</p> <p>Setting dynamic brightness (constant brightness = 0) doubles the communication overhead. May affect latency.</p> <ul> <li>if you want HyperHDR to restore to the original state it found at startup when turned off, check the option: <code>restore lights' original state when disabled</code></li> </ul>"},{"location":"Home.html","title":"Home","text":"<p>Welcome to the HyperHDR wiki!  </p> <p>I'd suggest starting with a list of the hardware components: needed components Also you may want to visit the software installation manual and finally go through the quick start guide</p>"},{"location":"Hue-Entertainment-API-v2.html","title":"Hue gradient light strips","text":"<p>HyperHDR supports Hue gradient light strips using the new Entertainment API V2, which should also work with other types of Philips lamps. You will need the Philips Hue app to configure your lights and bridge first. For Android, you can find it here: link</p> <p></p>"},{"location":"Hue-Entertainment-API-v2.html#philips-hue-app-configuration","title":"Philips Hue app configuration","text":"<p>Now we configure Philips Hue app: create a new entertainment group and position our lights (you just need to keep them separated / one light per each channel).</p>"},{"location":"Hue-Entertainment-API-v2.html#hyperhdr-configuration","title":"HyperHDR configuration","text":"<p>Exit Philips Hue app. Open HyperHDR configuration page. If you are using multiple light sources, create a new instance, start it and switch to it using the menu in the top-left section. </p> <p>Go to LED Hardware tab. In the controller type select <code>philipshue</code> and check both <code>Use Hue Entertainment API</code> and <code>Use Hue Entertainment API V2</code></p> <p>Tip</p> <p>If you decide to disable the linear output for the Hue lamps there, you can choose to increase the gamma in the processing tab, for example, to 2.2. Disabling this option is recommended because then the gamma is taken into account during the smoothing process. If it is enabled, it is applied afterward at the final stage before sending the colors to the lamp, which may result in slightly less smooth color transitions.</p> <p></p> <p>Your Hue bridge should be found. Otherwise you must put its IP address manually. Now click on the <code>Create a new User and clientkey</code> button. In the next step, you will be asked to press a button on the Hue bridge. </p> <p>You should find your Hue entertainment group here. Click on the <code>Use configuration ID</code> button. </p> <p>Now you can configure your lights (channels) position and size. You can also edit it more precisely in the next step. Save your configuration now. </p> <p>If you are not satisfied with the position of the Hue lamp or the area of the screen it reflects, go to the <code>LED Hardware</code> tab then select <code>LED Layout</code> on the top. Click on the <code>Zoom</code> button to make the editor more accessible and readable. Right-click on the selected lamp. Now you can change its position, size and force identification (blinking). </p>"},{"location":"HyperSerial.html","title":"HyperSerialPico and others","text":"<p>Advanced configuration and diagnostic for ESP &amp; Raspberry Pi Pico board with uploaded HyperSerialEsp8266, HyperSerialESP32 or HyperSerialPico (requires HyperHDR v20 or newer) firmware. </p> <p>Note</p> <p>Currently Raspberry Pi Pico boards are recommended. There are even LEDs-specialized models of Pico boards from Adafruit or Pimoroni equipped with a 3.3V to 5V level shifter, so you don't have to add anything or solder to them. They cost around 10-15$ depending on the model.</p> <p>What is unique compared to the Esp8266/ESP32/ESP32-S2 boards, Pico thanks to the PIO I/O coprocessor is able to produce a very high quality and precise signal. Which is especially required for the Neopixel sk6812/ws8212b LED strips. The signal from the ESP boards is usually well tolerated by most variants of the Neopixel LED strip, but the emulation of their protocol brings with it various side effects, such as high memory consumption (limitation of the maximum length of the LED strips), slightly drifting I2S data clock (still within LEDs tolerance), IRQ thunderstorm when RMT is used, etc. My tests of the Pico board together with practical measurements of signal timings allow us to conclude that this board is free of these drawbacks and still it is very cheap: ~$2 for the mini version (which is fully functional and works well) and $3-4 for the larger version with full GPIO connector.</p> <p>Find out more here:  - https://github.com/awawa-dev/HyperSerialESP32 - https://github.com/awawa-dev/HyperSerialEsp8266 - https://github.com/awawa-dev/HyperSerialPico</p> <p>Esp8266/ESP32/rp2040 handshake option:  </p> <p></p> <p>that allows: - reset the ESP32/Esp8266 board at the beginning - after the reset is performed, we read the initial HyperSerialEsp8266/HyperSerialESP32 boot message and check it </p> <ul> <li> <p>if the board is not capable of the 2Mb speed (or any other speed set in HyperHDR) the user will see a warning  </p> </li> <li> <p>after the LED device is stopper, we read the statistics (just wait few seconds). Still we maintain one way communication at the same time, because of problems with the performance of duplex for certain system/drivers. </p> </li> </ul> <p></p> <p></p> <p>If you have the 'Continuous output' option disabled, you may see dropped frames in the statistics (trash\u2011can icon). With this option off, HyperHDR saves resources by skipping RGB frame updates to the LED device more often than once per second if the frames are identical. Otherwise, these statistics may indicate that the LED rendering queue is becoming clogged:</p> <p></p>"},{"location":"Infinite-color-engine.html","title":"Infinite Color Engine \ud83c\udd95","text":""},{"location":"Infinite-color-engine.html#what-is-the-infinite-color-engine","title":"What is the Infinite Color Engine?","text":"<p>In short, it marks a clean break from the old 24-bit color space, moving to floating-point precision while still maintaining performance.  </p> <p>You might ask: Why bother, if most sources don\u2019t provide more than 24-bit color, except perhaps the P010 format? </p> <p>Well, here\u2019s the thing: such sources have always been available - even with something as basic as a cheap MS2109 grabber or flatbuffers external source.  In our application, when averaging colors for each LED, we\u2019ve always had access to a high-precision theoretical color space.  Until now, that precision was being brutally truncated to 24-bit.</p> <p>Another hidden \u201csource\u201d of precision has long been smoothing, which interpolates intermediate colors.  </p> <p>This entire subsystem has now been rewritten to handle floating-point numbers at both input and output.  </p>"},{"location":"Infinite-color-engine.html#what-does-this-mean-in-practice","title":"What Does This Mean in Practice?","text":"<ul> <li>The obvious: using the possibilities of lamps that offer support for an extended color palette </li> <li>Reduced banding, noise, and flicker  </li> <li>More stable color transitions across frames  </li> <li>Smoother post-processing corrections  </li> </ul> <p>Previously, when the final averaged color happened to fall on the boundary between two integers, even tiny changes in the source could trigger sudden jumps between frames.  </p> <p>By switching to floating-point, this issue has been drastically minimized.</p>"},{"location":"Infinite-color-engine.html#hardware-support","title":"Hardware Support","text":"<p>Extended color support is now available in drivers for:</p> <ul> <li>All Philips Hue lamps using the Entertainment API (v1 &amp; v2) </li> <li>LIFX lamps</li> <li>HD108 </li> </ul>"},{"location":"Infinite-color-engine.html#why-infinite","title":"Why \u201cInfinite\u201d?","text":"<p>The name isn\u2019t just marketing. The Infinite Color Engine works with a color palette of 1.24 \u00d7 10\u00b2\u2077 possible values. For comparison: - Old 24-bit color: 1.67 \u00d7 10\u2077 values - New floating-point engine: 1.24 \u00d7 10\u00b2\u2077 values </p> <p>The difference is, quite literally, astronomical. \ud83c\udf0c</p>"},{"location":"Infinite-color-engine.html#new-smoothing-algorithms","title":"New smoothing algorithms","text":"<p>In addition to the transition to floating-point numbers, the focus was on adding parameters that control the abruptness of color changes (brightness limiter or averaging with the previous frame) and adding the ability to work in the YUV space, not just RGB.</p> Title Description Linear Interpolator The Linear Interpolator is an adaptation of a legacy algorithm from previous HyperHDR versions, rewritten to use floating-point arithmetic for higher precision. It works by linearly interpolating the current color towards a target color, ensuring the transition completes over a defined duration regardless of the frame rate. Its key characteristic is the ability to smoothly retarget mid-animation, initiating a new, full-duration transition from its current state toward the new goal. RGB Infinite Interpolator This algorithm smoothly animates RGB colors over a set duration, offering two distinct modes for the transition. The first is a direct linear interpolation for a straight path between colors, while the second is a smoothed mode where the current color gracefully 'chases'' the target to create an ease-in/ease-out effect. A key feature is its ability to intelligently rescale an animation's duration when interrupted, ensuring a perceptually constant speed of change. YUV Infinite Interpolator This algorithm smoothly interpolates colors by operating in the YUV color space for more perceptually uniform transitions. Its main feature is limiting the rate of luminance change in each step, preventing sudden, jarring flashes of brightness. This ensures a visually pleasing effect, even if it extends the animation beyond its initially set duration to maintain that smoothness. Hybrid Physics Infinite Interpolator RGB (default) This algorithm smoothly transitions between colors using a hybrid physical model. A linear 'pacer' defines the direct path and timing to the target color, while the actual output color follows this pacer like an object attached to a damped spring. This two-part approach creates fluid, natural-looking animations with customizable inertia and overshoot, all while operating in the RGB color space. Hybrid Physics Infinite Interpolator YUV Version of Hybrid Physics Infinite Interpolator that works in the YUV colorspace where you can apply brightness limit. Exponential Infinite Interpolator Classic exponential implementation of smoothing updates LED colors toward a target, reacting quickly to large differences and slowing as they approach the target, producing smooth, natural ambient lighting transitions."},{"location":"Infinite-color-engine.html#infinite-color-engine-24-bit-anti-flickering-filter-v22beta2","title":"Infinite Color Engine: 24-bit Anti-Flickering Filter (v22beta2)","text":"<ul> <li> <p>New smoothing architecture rewritten from scratch to leverage a high-precision float pipeline. </p> </li> <li> <p>Replaces legacy integer-based delta blocking, which often \"froze\" slow transitions because it couldn't perceive sub-integer movement between steps.</p> </li> <li> <p>Implements RGB hysteresis on floating-point values: ensures the engine \"sees\" the full trajectory of a color, only committing an update when it's certain to land on a stable new 8-bit level.</p> </li> <li> <p>Uses coordinated updates (max-delta) instead of per-channel blocking to maintain perfect hue integrity and prevent chromaticity shifts during ultra-slow fades.</p> </li> <li> <p>Exceptionally effective when paired with inertia-based smoothing, such as the Hybrid Physics Infinite Interpolator RGB, where it stabilizes high-precision physical motion on standard LED hardware.</p> </li> <li> <p>Automatically bypassed for deep-color or high-precision drivers (e.g., HD108, LIFX, or Philips Hue in Entertainment Mode) that don't suffer from 8-bit quantization limits.</p> </li> </ul>"},{"location":"Infinite-color-engine.html#processing-pipeline-before--now","title":"Processing Pipeline (Before \u2192 Now)","text":"<p>\u2b07\ufe0f 1. Video Frame Area Averaging for LED - Before: color (float) truncated to 24-bit at output - Now: output remains as float  </p> <p>\u2b07\ufe0f 2. Post-Processing - Before: received, processed in pipeline, and output 24-bit color. some functions, such as changing luminance or saturation, could use float, but they still received and output 24-bit color - Now: both processing and input/output work on float colors  </p> <p>\u2b07\ufe0f 3. Smoothing - Before: input/output in 24-bit color, internal processing on float - Now: input, processing, and output all on float colors  </p> <p>\u2b07\ufe0f 4. LED Drivers - Before: always received and rendered 24-bit color - Now: if the device supports it (Philips Hue, HD108) \u2192 rendering at higher precision;   otherwise \u2192 fallback to 24-bit rendering  </p>"},{"location":"Infinite-color-engine.html#the-post-processing-pipeline-before--now","title":"The post-processing Pipeline (Before \u2192 Now)","text":""},{"location":"Infinite-color-engine.html#old-approach-24-bit-pipeline","title":"Old approach (24-bit pipeline)","text":"<ul> <li>Operated directly on 8-bit nonlinear sRGB values.  </li> <li>Every transformation (brightness, per-channel gamma, calibration, temperature, backlight) worked on already quantized integers \u2192 rounding/precision loss at every step.  </li> <li>Per-channel gamma correction was not equivalent to standard gamma adjustment, and could distort hues \ud83d\ude2c.  </li> <li>Input being nonlinear made operations like calibration and saturation adjustment less accurate (they are meant to be done in linear space).  </li> </ul>"},{"location":"Infinite-color-engine.html#new-approach-float3-pipeline","title":"New approach (float3 pipeline)","text":"<ul> <li>Operates first in linear sRGB space with float precision \u2192 avoids cumulative rounding errors.  </li> <li>Color temperature applied first: tinting works best before calibration so that calibration LUT/matrix can correct consistently.  </li> <li>Calibration in colorspace applied in linear domain \u2192 mathematically correct, ensures LUT/matrix is used as designed.  </li> <li>Scale color output (user parameter)  </li> <li>Convert back to nonlinear sRGB only once: avoids repeated conversions and precision loss.  </li> <li>Global user gamma correction applied consistently on all channels \u2192 perceptually uniform adjustment \u2705.  </li> <li>Brightness and saturation after calibration: adjusting perceptual properties after ensuring primaries are correct.  </li> <li>Minimal backlight last: guarantees final safety floor regardless of prior adjustments.  </li> <li>Limit power output:  scale down only if the power limit (user parameter) is exceeded</li> </ul> <p>\ud83d\udc49 Overall: the new pipeline is much more accurate, perceptually consistent, and scientifically correct. The old one was simpler but mathematically flawed.  </p> Old approach (24-bit) New approach (float3) Input: sRGB nonlinear \ud83d\ude2c (24-bit).All further steps already lose accuracy due to rounding \ud83d\ude2c Input: sRGB linear (float3).Correct starting point for calibration &amp; math \u2705 Steps:1. Apply Brightness &amp; Saturation2. Apply User Gamma per channel \ud83d\ude2c3. Calibrate in Colorspace (on nonlinear data \ud83d\ude2c)4. Apply Color Temperature5. Apply Minimal Backlight Steps:1. Apply Color Temperature (before calibration \u2705)2. Calibrate in Colorspace (linear domain \u2705)3. Scale color output (user parameter \u2705)4. Convert to nonlinear sRGB (only once \u2705)5. Apply User Gamma (global, consistent \u2705)6. Apply Brightness &amp; Saturation (perceptual ops \u2705)7. Apply Minimal Backlight (final floor \u2705) 8. Limit power output (scale down only if the power limit is exceeded \u2705) Output: sRGB nonlinear (24-bit). Output: sRGB nonlinear (float3 \u2192 quantized later)."},{"location":"Installation.html","title":"Installation","text":"<p>Warning</p> <p>The guide has been updated for incoming HyperHDR v22 version.</p>"},{"location":"Installation.html#windows","title":"Windows","text":"<ul> <li> <p>Download HyperHDR installer for Windows from HyperHDR github project. For example: <code>HyperHDR-22.0.0-Windows-AMD64.exe</code></p> </li> <li> <p>Uninstall previous version of HyperHDR (if applied). </p> </li> <li> <p>Run the installer. Windows probably will ask are you sure? It's default behavior for the first time usage for files downloaded from the internet without EV certificate which costs a lot. </p> </li> <li> <p>Then proceed with the installer... just click few times 'next' and 'finish'. </p> </li> <li> <p>Run the HyperHDR from the desktop shortcut.</p> </li> <li> <p>The HyperHDR icon will show up in the right-bottom corner</p> </li> <li> <p>Click it the right button. The menu will show up. Then select 'Settings'. The browser will open HyperHDR www panel.</p> </li> </ul>"},{"location":"Installation.html#debian-and-ubuntu-apt-repository","title":"Debian and Ubuntu (APT repository)","text":"<p>For the latest versions of Debian and Ubuntu, you can use our APT repository to install or update HyperHDR. The repository is located at https://awawa-dev.github.io</p> <p>For very old Raspberry Pi platforms based on the ARMv6 architecture, like the Raspberry Pi Zero (not to be confused with the Raspberry Pi Zero 2 W), the latest installers we build and deliver are for the Debian Bookworm-based version. However, if you're on a newer system, you can build them yourself from source or try installing the Bookworm version.</p> <p>1) Installing     All HyperHDR SD images since version v19beta2 are linked to the HyperHDR repository so you don't need this step if you use it.     If you have HyperHDR manually installed from Github or are using old SD images before v19beta2, remove HyperHDR first: <pre><code>sudo apt remove hyperhdr\n</code></pre>     Add HyperHDR repository and install the application: <pre><code>type -p curl &gt;/dev/null || sudo apt install curl -y\ncurl -fsSL https://awawa-dev.github.io/hyperhdr.public.apt.gpg.key | sudo dd of=/usr/share/keyrings/hyperhdr.public.apt.gpg.key \\\n&amp;&amp; sudo chmod go+r /usr/share/keyrings/hyperhdr.public.apt.gpg.key \\\n&amp;&amp; echo \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/hyperhdr.public.apt.gpg.key] https://awawa-dev.github.io $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/hyperhdr.list &gt; /dev/null \\\n&amp;&amp; sudo apt update \\\n&amp;&amp; sudo apt install hyperhdr -y\n</code></pre></p> <p>2) Upgrade     If you already have a HyperHDR repository set up, you can easily update HyperHDR later: <pre><code>sudo apt update &amp;&amp; sudo apt install hyperhdr -y\n</code></pre></p>"},{"location":"Installation.html#hyperhdr-custom-raspberry-pi-os-distribution","title":"HyperHDR custom Raspberry Pi OS Distribution","text":"<p>Our SD image includes pre-installed HyperHDR with P010 Kernel Fix. The system image is built in the https://github.com/awawa-dev/P010_for_V4L2 repository thanks to Github Action and Raspberry Pi OS base image. We only support the 64-bit architecture, which allows our application to achieve its maximum performance.</p> <ul> <li> <p>Download and extract the SD image from HyperHDR Github release repository. 7-zip is recommended.  </p> </li> <li> <p>Download Rufus: link. We do not recommend using the Raspberry Pi Imager for this installation, as it may interfere with certain settings, including the HyperHDR startup service.</p> </li> <li> <p>Insert prepared SD to the reader. Check the reader's letter assigned in Windows. <ol> <li>Select the img file that you extracted from the downloaded archive</li> <li>Verify that the program selected correct SD card drive's letter</li> <li>Click 'Start' to begin the process of writing</li> </ol></p> </li> <li> <p>After the image is written successfully probably you want to configure the Wifi connection for Raspberry Pi.</p> </li> <li> <p>Debian Trixie expects Wi-Fi configuration to be in a file named <code>wifi.nmconnection</code> located on the SD card (drive named <code>bootfs</code>). Open this file and edit its contents. For example:   <pre><code># Uncomment everything below this line and set your ssid and password\n[connection]\nid=wifi\nuuid=f81d4fae-7dec-11d0-a765-00a0c91e6bf6\ntype=wifi\ninterface-name=wlan0\n\n[wifi]\nmode=infrastructure\nssid=NAME_OF_YOUR_WIFI\n\n[wifi-security]\nauth-alg=open\nkey-mgmt=wpa-psk\npsk=WIFI_PASSWORD\n\n[ipv4]\nmethod=auto\n\n[ipv6]\naddr-gen-mode=default\nmethod=auto\n\n[proxy]\n</code></pre></p> </li> <li> <p>Take the SD out of the card reader and put it into the Raspberry Pi.</p> </li> </ul> <p>After boot default host name is: hyperhdr Connect to the www panel using port 8090 (HTTP) or 8092 (HTTPS). Default user is: <code>pi</code> Default password is: <code>raspberry</code> For security reasons, you may consider changing the password for pi user after the first boot. \u26a0\ufe0f SSH and SPI are enabled on default.  </p>"},{"location":"Installation.html#linux","title":"Linux","text":"<ul> <li> <p>Connect to your Linux OS using SSH client (putty) or using keyboard/monitor. Log in with your default user.  </p> </li> <li> <p>First uninstall the previous version of HyperHDR (if applied):  <code>sudo apt remove hyperhdr</code></p> </li> <li> <p>Go to the tmp directory:  <code>cd /tmp</code></p> </li> <li> <p>Download the package from HyperHDR Github release section to the current <code>tmp</code> directory.</p> <ul> <li> <p>Raspberry Pi OS 32bits choose <code>armhf</code> suffix. For example: <code>wget https://github.com/awawa-dev/HyperHDR/releases/download/v22.0.0/HyperHDR-22.0.0-Linux-armhf.deb</code></p> </li> <li> <p>Raspberry Pi OS 64bits choose <code>aarch64</code> suffix. For example: <code>wget https://github.com/awawa-dev/HyperHDR/releases/download/v22.0.0/HyperHDR-22.0.0-Linux-aarch64.deb</code></p> </li> <li> <p>Generic x86 Linux: choose <code>amd64</code> suffix. For example: <code>wget https://github.com/awawa-dev/HyperHDR/releases/download/v22.0.0/HyperHDR-22.0.0-Linux-amd64.deb</code></p> </li> </ul> </li> <li> <p>Install the package that you have downloaded from the current directory. For example: <code>sudo apt install ./HyperHDR-22.0.0-Linux-aarch64.deb</code></p> </li> <li> <p>HyperHDR should be up and running on the 8090 (HTTP) or 8092 (HTTPS) port.</p> </li> <li> <p>If the WWW panel is out of reach then run the following command to check what's happening: <code>/usr/bin/hyperhdr -d</code> </p> </li> <li> <p>To start/stop HyperHDR service on Raspberry Pi execute: <code>sudo systemctl start/stop hyperhdr@pi.service</code></p> </li> </ul>"},{"location":"Installation.html#macos","title":"macOS","text":"<p>HyperHDR provides a very user-friendly native DMG installation container for both Intel and arm64 (M1\u2013M4) platforms.  </p> <ul> <li>Download and mount the DMG container. The setup installation process will start, and you will be prompted to install the application on your system. To do that, drag the HyperHDR icon to your Applications folder.</li> </ul> <p></p> <ul> <li> <p>HyperHDR should then be available in your Finder's Applications folder. Launch it. After the application starts, macOS will ask you to grant camera permission for HyperHDR. This is required. If you missed the request, you can always change your choice later in macOS System Settings. A similar dialog for granting microphone permission will appear when you use the sound effects or the system software screen grabber for the first time (an application restart is required in this case).</p> </li> <li> <p>While HyperHDR is running, it displays an icon ('H') in the upper-right corner. You can use it to open the menu, which contains the 'Settings' option that allows you to open the browser with the HyperHDR configuration panel.</p> </li> </ul> <p></p> <ul> <li>Now it's time to go through the typical HyperHDR configuration process.  </li> </ul> <p></p>"},{"location":"Instance-synchronization.html","title":"Instance synchronization","text":""},{"location":"Instance-synchronization.html#synchronization-between-different-hyperhdr-devices","title":"Synchronization between different HyperHDR devices","text":"<p>There are cases when we want HyperHDR to work with instances on other devices. For example, one instance of HyperHDR on Raspberry Pi working with a USB grabber and LEDs is sometimes also intended to display colors based on a Windows PC screen (no grabber and no LEDs attached, only built-in DirectX software capture as a video source for RPi instance).</p> <p>Connect a HyperHDR instance on Windows (a remote video/colors source) to another HyperHDR instance on RPi (HyperHDR actually acts similar to WLED here as a LED driver) using the UDP raw sender/receiver mechanism.</p> <p>This makes synchronization even faster because we do not send entire images over the network (when flatbuffers or protobuffers are used), only the colors of the RGB LEDs, and therefore much smaller packets.</p> <p></p> <p>Both instances must have the same number of LEDs and the same geometry. An example path for our configuration: - you need to export/backup the HyperHDR configuration from RPi (interface: General tab) - import the configuration backup on Windows (interface: General tab) - on Windows change the light source to 'udpraw' (interface: 'LED hardware' tab) and set the target IP to the Raspberry Pi address - on Windows disable USB grabber and enable DirectX grabber (interface: Video capturing tab) - on Windows disable 'Smoothing' (interface: Image Processing tab) Otherwise, it will be processed twice: once on Windows and once on RPi - on Windows disable 'Image processing' settings that may have affect LED colors. For example for the red/green/blue gamma settings, change 1.5 to neutral 1 (interface: Image Processing tab). Otherwise, they will be processed twice: once on Windows and once on RPi - on Raspberry Pi, you need to enable the UDP server (interface: Advanced-&gt;Network Services tab, screenshot above)  </p>"},{"location":"JSON-API.html","title":"JSON API","text":"<p>HyperHDR interface includes a simple built\u2011in form that automatically generates the necessary commands with just a few clicks. This tool makes it easy to remotely control selected HyperHDR functions, for example switching USB grabbers or LEDs on and off, without having to type commands manually. It does not require in\u2011depth knowledge of the API or programming skills, since the form handles everything for you.  </p> <p>JSON commands can be delivered via HTTP/HTTPS using GET or POST methods, and they can also be sent through MQTT, provided that you have configured the broker connection in HyperHDR.</p> <p></p> <p>For example:</p> <p>You can remotely control the HDR tone mapping state using for example Home Automation system. If you are using Home Assistant and Denon amplifier, it's possible to automatically switch it depending on the actual video stream format (example).</p> <p>Turning HDR tone mapping OFF: <code>http://IP_OF_HYPERHDR:8090/json-rpc?request={%22command%22%3A%22videomodehdr%22%2C%22HDR%22%3A0}</code></p> <p>Turning HDR tone mapping ON: <code>http://IP_OF_HYPERHDR:8090/json-rpc?request={%22command%22%3A%22videomodehdr%22%2C%22HDR%22%3A1}</code></p> <p>Getting HDR tone mapping state (search for videomodehdr property): <code>http://IP_OF_HYPERHDR:8090/json-rpc?request={%22command%22%3A%22serverinfo%22}</code></p>"},{"location":"LUT-calibration.html","title":"Video source LUT calibration","text":"<p>HyperHDR v21 introduced a much simplified color calibration procedure and from now on, all you need to do is play the calibration MP4 file in your favorite video player and HyperHDR will take care of the rest. You no longer need a PC and use a browser to calibrate HDR, which was very inconvenient and in addition it did not calibrate the video player itself, although this option is still there if you want.</p> <p>HyperHDR v21 was also the first to introduce the NV12 format to flatbuffers. And it is not just an empty convenience because thanks to LUT tables, the resource-consuming and CPU-intensive conversion of NV12 to RGB is eliminated and we can also detect which YUV coef was used by the source. Without LUT and calibration NV12 in flatbuffers, it is just a dummy so called \"feature\" that even worsens the previous RGB solution. Anyway you can test flatbuffers with and without NV12 enabled and then see in the <code>top</code> command a positive effect in CPU load and memory usage of capturing backend + HyperHDR processes. Remember that piccap may ignore NV12 format for GUI capturing.</p>"},{"location":"LUT-calibration.html#preparation","title":"Preparation","text":"<p>Remember the following assumptions: - calibration only supports YUV/NV12/MJPEG/P010 formats - recommended resolution (it does not affect the load during calibration) is 1920x1080. So if you have the \"Quarter of frame mode\" or \"blackbar detector\" option enabled in the grabber, you must disable them for the calibration time.</p> <p>Download the HDR calibration file calibration_HDR_yuv420_limited_range.mp4. If for some reason you want to calibrate SDR (e.g. for webOS) then use: calibration_SDR_yuv420_limited_range.mp4.  </p> <p>Later after the calibration process is complete you can test &amp; play this HDR file for_testing_after_calibration_HDR_yuv420_limited_range.mp4 and check the result in the HyperHDR live preview window.</p> <p>If you want to calibrate LUT for webOS, it is recommended to either not enable LCH color correction or redirect a piccap stream to your computer and use it as a calibration instance, and then upload the finished LUT to webOS. Unlike the previous version, the current calibration process heavily loads all CPU cores.</p>"},{"location":"LUT-calibration.html#hyperhdr-procedure","title":"HyperHDR procedure","text":"<p>Open the calibration page</p> <p></p> <p>You can enable <code>LCH color correction</code>, which can significantly improve results, but also causes a significant load on the processor. On the other hand, calibration is only done once, but make sure the processor has adequate cooling. Do not enable LCH correction for P010 video format, as it does not need it at all.</p> <p>Open the video preview and start playing the test file on your player. You should see dots like in the picture. Then start the calibration. You have to do it rather quickly, because the calibration file is 90 seconds long and the calibration needs about 20 continuous seconds from anywhere in the video. Make sure there is no player interface in the live preview, e.g. progress bar or \"Now playing\" texts etc. You can close the video preview window to save resources.</p> <p>For HDR test video pay attention to whether the video has triggered HDR mode on your TV. Otherwise something is wrong with the video player.</p> <p></p> <p>After a few seconds, you should see confirmation that calibration is working correctly and HyperHDR has recognized the first calibration frames.</p> <p></p> <p>And after a few minutes it's ready. That's it. You can see detailed calibrated colors in the logs right after calibration.</p> <p></p>"},{"location":"LUT-calibration.html#combining-calibrated-sdr-and-hdr-lut-tables-into-one","title":"Combining calibrated SDR and HDR LUT tables into one","text":"<p>If you want to combine calibrated SDR LUT table and HDR LUT table and you are using USB grabber with YUV/NV12/P010 format then you can use this command: <code>dd bs=1 skip=50331648 count=50331648 seek=100663296 if=sdr_input_lut of=hdr_input_and_output_lut</code></p> <p>The input/output <code>hdr_input_and_output_lut</code> will contain calibrated data both for SDR and HDR video source.</p>"},{"location":"LUT-calibration.html#support-for-zstd-compressed-lut","title":"Support for ZSTD compressed LUT","text":"<p>Required tool: an application that can compress files using ZSTD. For example ZSTD Fork of 7-zip with a support of ZSTD compression https://github.com/mcmilk/7-Zip-zstd</p> <p>Use 7-zip ZS. Right click on the uncompressed LUT file: <code>7-zip ZS</code> \u21d2 <code>Add to archive...</code> You should see the 7-zip compression settings. 1. Select zstd compression.  2. Recommended compression level is 17 - maximum. 3. Do not change the proposed filename.  4. After creating the compressed LUT, delete the uncompressed LUT file. </p> <p></p> <p>HyperHDR should automatically recognize that the uncompressed file does not exist and will try to find a compressed file with the additional <code>.zst</code> extension.</p>"},{"location":"LUT-calibration.html#lut-trimming-before-zstd-compression","title":"LUT trimming before ZSTD compression","text":"<p>If you are using only calibrated LUTs for NV12/YUV (so tone mapping is also always enabled) you can trim these LUTs for better compression ratio and decompression speed:</p> <pre><code>fsutil file setzerodata offset=0 length=50331648 &lt;lut_filename&gt;\nfsutil file setzerodata offset=100663296 length=50331648 &lt;lut_filename&gt;\n</code></pre>"},{"location":"Level-Shifter.html","title":"3.3V to 5V level shifter","text":"<p>The 3.3V level shifter is a mandatory part of the solution where 3.3V GPIO device like Raspberry Pi or ESP8266/ESP32 is communicating with the 5V LED strip.</p> <p>The diagram of the board for WS2812b/SK6812 including ESP32/ESP8266 and the SN74AHCT125N 74AHCT125 level shifter. Thanks @wilhelmthorpe</p> <p> </p> <p> </p> <p> </p>"},{"location":"LibreELEC.html","title":"LibreELEC","text":"<p>Warning</p> <p>HyperHDR has been officially included in the LibreELEC distribution so you can install it directly from the system.</p> <p>I have prepared an official native LibreELEC HyperHDR v20beta addon for RPi4/5 and x86_64. Copy it on pendrive and just install via Kodi Addons (Kodi: System \u21d2 Add-ons \u21d2 install from zip file). It works right after installing, no need to manually modify system files/services. Note that you still need a USB grabber to capture video. LED drivers such as HyperSerialPico work fine.</p>"},{"location":"LibreELEC.html#download","title":"Download","text":"<p>Download ready to use add-ons for Raspberry Pi 4 and standard PC (x86_64) LibreELEC 12 platforms: https://github.com/awawa-dev/LibreELEC.tv/releases</p> <p>You can find the add-on sources here on my LibreELEC 12 fork: https://github.com/awawa-dev/LibreELEC.tv/tree/libreelec-12.0-hyperhdr</p>"},{"location":"LibreELEC.html#compiling","title":"Compiling","text":"<p>If you need it for another platform, just build it yourself using my LibreELEC fork (actually my last commit which includes the HyperHDR add-on). Follow the general instructions from LibreELEC, e.g. to build an add-on for Raspberry Pi 4 you need these two commands:</p> <p>LibreELEC 12: <pre><code>PROJECT=RPi ARCH=aarch64 DEVICE=RPi4 make image\nPROJECT=RPi DEVICE=RPi4 ARCH=aarch64 ./scripts/create_addon hyperhdr\n</code></pre></p> <p>PC(x86_64): <pre><code>PROJECT=Generic ARCH=x86_64 DEVICE=Generic make image\nPROJECT=Generic DEVICE=Generic ARCH=x86_64 ./scripts/create_addon hyperhdr\n</code></pre></p> <p>Sometimes it takes several executions to successfully build a base image: first command with 'make image', probably LibreELEC building nuances, it doesn't happen every time. The building process is intense and can take several hours! Although Ubuntu 22.04 LTS is not guaranteed by LibreELEC as a build host OS, it worked for me.</p> <p></p> <p></p>"},{"location":"LinuxUpdateScript.html","title":"LinuxUpdateScript","text":"<p>The script is in the testing phase: <pre><code>#!/bin/bash\n\n############################################################\n# 'HyperHDR_update.sh' script to install/upgrade HyperHDR  #\n#                                                          #\n# v3 :                                                     #\n#  - checking existing version works if none installed     #\n#  - added \"-f\" param to force install of latest version   #\n#                                                          #\n############################################################\n\n#Default params\nFORCE_LATEST_INSTALL=0\nVERBOSE_MODE=0\n\nfunction readParams () {\n  until (( $# == 0 )); do\n    case $1 in\n      \"-f\")\n        FORCE_LATEST_INSTALL=1\n        echo \" Opt: forcing latest version installation\"\n        shift\n        continue\n        ;;\n      \"-v\")\n        VERBOSE_MODE=1\n        echo \" Opt: verbose mode\"\n        shift\n        continue\n        ;;\n      *)\n        echo \" Opt: unknown '$1' parameter =&gt; ignored...\"\n        shift\n        continue\n        ;;\n    esac\n  done\n}\n\n#Is Curl installed ?\nwhich curl 1&gt;/dev/null\nif [ $? != 0 ]; then\n  sudo apt update &amp;&amp; sudo apt install curl -y\nfi\n\n#Is GitHub CLI installed ?\nwhich gh 1&gt;/dev/null\nif [ $? != 0 ]; then\n  sudo curl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg | sudo dd of=/usr/share/keyrings/githubcli-archive-keyring.gpg &amp;&amp; sudo chmod go+r /usr/share/keyrings/githubcli-archive-keyring.gpg &amp;&amp; echo \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main\" | sudo tee /etc/apt/sources.list.d/github-cli.list &gt; /dev/null &amp;&amp; sudo apt update &amp;&amp; sudo apt install gh -y\nfi\n\n#Check parameters\nreadParams $*\n\nif [ $FORCE_LATEST_INSTALL = 1 ]; then\n  versionSelected=$(sudo gh release list -R awawa-dev/HyperHDR -L 2 | cut -d'v' -f2 | cut -f1 | awk '{print $1}' | head -1)\nelse  \n  #Select version\n  echo\n  echo \"Select version to install :\"\n  currentVersion=$(hyperhdr --version 2&gt; /dev/null | head -2 | tail -1 | awk '{print $3}')\n  if [ currentVersion = \"\" ]; then\n    currentVersion=\"none\"\n  fi\n  echo \" (currently installed version = '${currentVersion}')\"\n  sudo gh release list -R awawa-dev/HyperHDR -L 2 | cut -d'v' -f2 | cut -f1 | awk '{print \" \", NR, \"-&gt;\", $1}'\n  echo \"  (any other key to cancel...)\"\n  echo\n  read versionNumber\n\n  case \"${versionNumber}\" in\n    1)\n      #Get latest version\n      versionSelected=$(sudo gh release list -R awawa-dev/HyperHDR -L 2 | cut -d'v' -f2 | cut -f1 | awk '{print $1}' | head -1)\n      ;;\n    2)\n      #Get previous version\n      versionSelected=$(sudo gh release list -R awawa-dev/HyperHDR -L 2 | cut -d'v' -f2 | cut -f1 | awk '{print $1}' | tail -1)\n      ;;\n    *)\n      echo \"Exiting...\"\n      exit 0\n      ;;\n  esac\nfi\n\necho\ncd /tmp\necho \"#################################\"\necho \"Downloading ${versionSelected}...\"\necho \"#################################\"\nsudo wget https://github.com/awawa-dev/HyperHDR/releases/download/v${versionSelected}/HyperHDR-${versionSelected}-$(uname -s)-$(uname -m).deb\nif [ $? != 0 ]; then\n  echo \"KO: impossible to download version ${versionSelected} !\"\n  sleep 2\n  exit 1\nfi\n\necho\necho \"############################\"\necho \"Removing previous version...\"\necho \"############################\"\nsudo apt -y remove hyperhdr\n\necho\necho \"##############################\"\necho \"Installing selected version...\"\necho \"##############################\"\nsudo apt -y install ./HyperHDR*.deb\nsudo systemctl start hyperhdr@pi.service\n\necho\necho \"########################\"\necho \"Post install cleaning...\"\necho \"########################\"\nsudo apt -y autoremove\nsudo rm -f ./HyperHDR*.deb\n\necho\necho \"#########################\"\necho \"Installation successful !\"\necho \"#########################\"\nexit 0\n</code></pre></p>"},{"location":"P010-video-format.html","title":"P010 high quality video format","text":"<p>In the past, this was a format reserved for very expensive USB grabbers such as the Elgato HD60X. It allows you to go further than typical 8-bit raw image capture, which is especially important for HDR. Currently, relatively inexpensive HDMI 2.0 grabbers are appearing on the market (although still much more expensive than the MS2130, but it is an HDMI 1.4 grabber and does not have an HDMI loop), which in addition to supporting e.g. VRR, also offer the P010 format. For licensing reasons, HDCP protected video stream is of course not recorded and still requires usage of HDMI splitters for ambient lighting.</p> <p>How does this affect the quality compared to typical grabbers? Since we usually get a raw image, it does not suffer from the typical distortions when a grabber tries to improve/process an HDR signal treating it as SDR. Another advantage is the resolution of up to 10-bits, which allows to reduce the quantization effect visible in the case of tone mapping of 8-bit video source.</p> <p>The P010 format is natively supported by Windows, but not by macOS and Linux... although in the case of Linux I myself added its support via a patch for the UVC module in the kernel. Thanks to this, Raspberry Pi users can also enjoy it. It can also be used for other platforms and Linux distributions. Patch source (MIT license) is here: p010.patch</p> <p>Note</p> <p>Of course, for Raspberry Pi users we have prepared a ready image that already contains the mentioned P010 patch, so they do not have to compile the Kernel themselves. The ready patched Raspberry Pi OS aarch64 SD image is in the HyperHDR 21 release section.</p> <p>Without my patch P010 will be not recognized in <code>dmesg</code> logs: </p> <p>Warning</p> <ul> <li>P010 format requires to perform simply LUT calibration: here. The default LUT won't work for P010 video format</li> <li>It is highly recommended to enable <code>Quarter of frame mode</code> in the grabber settings after calibration</li> <li>If you don't see P010 and other supposedly supported high-resolution modes, check your grabber USB-C cable</li> </ul>"},{"location":"Quick-start.html","title":"Quick start","text":""},{"location":"Quick-start.html#introduction","title":"Introduction","text":"<ol> <li>Must read</li> <li>HyperHDR basics</li> <li>How to create and enable your first LED strip (instance)</li> <li>Manual LED layout editing and testing</li> <li>Add your second instance e.g. Philips Hue lamps</li> <li>Configuring and testing your USB video grabber</li> <li>How to read HyperHDR statistics</li> <li>Infinite Color Engine \ud83c\udd95</li> </ol>"},{"location":"Quick-start.html#performance-pro-tips","title":"Performance pro-tips:","text":"<p>Although the use of WiFi LED drivers tempts with simplicity, in fact, for the entire duration of the session that requires constant data transmission, you will be at the mercy of the quality of the radio connection, the reliability and compatibility of your router with your esp8266 / esp32 model, the quality of the latter and the reliability of the given version e.g. Espressif SDK which was used to build the firmware. In addition, LED control can often lead to conflict with WiFi communication (especially \"IRQ thunderstorm\" if popular RMT method is used). You have been warned \u26a0\ufe0f </p> <p>Note</p> <ul> <li>Use the highest framerate for your USB grabber. General rule: highest framerate, lowest resolution. </li> <li>The best image quality after LUT calibration is definitely provided by the raw P010 codec. For SDR, you can also try using NV12 (or YUV) or MJPEG, although much depends on how much the grabber\u2019s internal processing will degrade the signal. A good example of how easily even an SDR signal can be ruined by faulty firmware \u2014 either \u201cimproved\u201d by sellers or simply due to its default settings \u2014 are the MS2109 and MS2130 grabbers, although certain remedies are available for them.</li> <li>Avoid using high recording resolutions (e.g., 1080p) unless explicitly required by the selected codec, such as P010. Higher resolutions have negligible influence on ambient light measurements but impose a significant load on system resources. When operating at such resolutions or when using the NV12 format, it is recommended to downscale the captured image to 25% within the grabber settings. Note that NV12 inherently includes redundant luminance information at the expense of chroma data, so additional downscaling has little practical impact on the resulting image quality.</li> <li>Because the communication speed between the unit and the video grabber directly affects latency, we strongly recommend using hosts and grabbers that support USB 3.0. Therefore, as a minimum, we suggest platforms such as the N100 or Raspberry Pi 4. Of course, USB 2.0 grabbers can also be used, but you should be aware that they introduce an additional delay of approximately 50 ms compared to USB 3.0 systems. This limitation is purely hardware-related.</li> <li>Maintain realistic \"Smoothing\" processing settings. Do not use a 60 Hz refresh rate for smoothing, for example, if your LED driver based on Arduino or using integration with Home Assistant or ZigBee can only output 20-25 Hz. Otherwise, you will clog the communication.</li> </ul>"},{"location":"Quick-start.html#first-steps","title":"First steps","text":"<p>Ok let's get started. Connect to HyperHDR using the address: <code>http://IP_OF_HYPERHDR:8090</code></p> <p></p> <p>Main menu is located on the left part of the page:</p> <p></p> <p>The instance switch button is disabled for now because there is only one instance at the beginning. There is a warning about setting a new password, so it's a good idea to do it now. Follow the link or go to the \"Advanced\" tab to change the password:</p> <p></p> <p>You may also be greeted with an error warning. Don't panic and go to the logs. In the example below, I made a mistake when entering the IP address of my Philips Hue Bridge:</p> <p></p>"},{"location":"Quick-start.html#configuring-the-led-strip","title":"Configuring the LED strip","text":"<p>First give a friendly name for our instance:  </p> <p></p> <p>The LED strip is controlled by USB high-speed HyperSerialWLED/HyperSerial8266/HyperSerialESP32. So go to the LED devices and select 'LED hardware' tab then adalight from the list.</p> <p></p> <p>On Raspberry Pi the COM list could be different. Remember that Rpi 3 &amp; 4 has available Bluetooth device that is enabled on default. Its exact path (e.g. ttyAMA0 here) may vary.</p> <p></p> <p>Because we use non-standard highspeed AWA protocol @2Mb we need to configure two more things:  </p> <p></p> <p>Now we need to set geometry of the LED strip. For example let's assume we have: input in the middle of the bottom, 50 LEDs at the top, 25 LEDs on the left/right.  At the bottom we 40 LEDs and a gap of 10 LEDs so you must put 50 LEDs (40 + 10) as bottom and set gap as 10. </p> <p></p> <p>Still there is a problem with the input position. Set gap &amp; input position to 95 (top 50 + right 25 + one of bottom part 20)</p> <p></p>"},{"location":"Quick-start.html#manual-led-layout-and-testing","title":"Manual LED layout and testing","text":"<p>If you are not satisfied with the automatically generated layout, you can correct it manually. Right-click on the selected LED and a context menu will be displayed. You can manually adjust its position (Move) or size (Properties), disable it (it will never be lit) or remove it (Delete) from the system altogether. </p> <p>Use 'Identify' to test a particular diode or check its physical location. This will cause it to blink for a few seconds.</p> <p></p>"},{"location":"Quick-start.html#second-instance-philips-hue-lamps","title":"Second instance (Philips Hue lamps)","text":"<p>First create new instance for our Philips Hue lamp:  </p> <p></p> <p>Now switch to the new instance:  </p> <p></p> <p>Tip</p> <p>If you decide to disable the linear output for the Hue lamps, you can choose to increase the gamma in the processing tab, for example, to 2.2. Disabling this option is recommended because then the gamma is taken into account during the smoothing process. If it is enabled, it is applied afterward at the final stage before sending the colors to the lamp, which may result in slightly less smooth color transitions.</p> <p>Before proceeding you must create an 'Entertainment group' for your lamps in the Philips Android or IOS mobile application. Don't even try without doing it first. Your Hue Bridge should also to be working for at least 2-3 minutes to avoid connection problems during configuration at startup. You should try first to send a color from the Philips mobile app to make sure it's working and your 'Entertainment group' is created.</p> <p>Then add Philips Hue light source and run the wizard:  </p> <p></p> <p>HyperHDR should find the Philips Hue bridge in the same sub-network. Some custom router's firewall rules or enabling WiFi isolation can cause the process to fail.</p> <p></p> <p>Click the 'Create new user and and clientkey' button. Now it's time to click a large hardware button located on your Hue bridge. It allows to authorize the HyperHDR's access. If everything goes OK you should have the Username and Clientkey filled in automatically. Identificator of 'Entertainment group' should also be found automatically.</p> <p></p> <p>Proceed with clicking the 'use group...' button.</p> <p></p> <p>Now you can assign area of the TV to single, selected lamp in the entertainment group. Because I have 2 lamps on the floor (one just on the right of the TV and second to the left) I selected following options.</p> <p> </p>"},{"location":"Quick-start.html#configuring-video--system-grabber","title":"Configuring video &amp; system grabber","text":"<p>Now we configure the video source for HyperHDR: it can be an USB grabber or system screen capture. Go to the 'Video capturing tab' and select your USB grabber.</p> <p></p> <p>The yellow 'Info' button will appear after you select the grabber. Click it to open the dialog. Ezcap 321 offers very high capturing modes. I choose the lowest NV12. You should not go above 720p, because it causes drain of CPU resources &amp; introduces video processing lag and gives very little to our ambient effect.</p> <p></p> <p>Next I check 'Quarter to frame mode' option. It will reduce the frame dimensions (to 50%) &amp; size (to 25%) but will not reduce color's data due to NV12 codec properties.</p> <p></p> <p>Click the 'Video preview &amp; LED visualization' button in the upper left corner:</p> <p></p> <p>The video stream colors are washed-out and overall luminescence is low. That's because we have captured a HDR10 video stream and almost none of USB grabbers can process HDR metadata so important part of information about the image is lost. Let's back to the Capturing hardware tab and enable 'HDR to SDR tone mapping'.</p> <p></p>"},{"location":"Quick-start.html#how-to-read-hyperhdr-statistics","title":"How to read HyperHDR statistics","text":"<p>The statistics are available on the main HyperHDR application page (the 'Overview' tab)</p> <p></p> <ol> <li>Overall CPU usage with per core visualization (by all running applications, not only HyperHDR)</li> <li>Available system memory</li> <li>Temperature reported by your hardware.</li> <li>Verify that the Raspberry Pi's built-in hardware sensor reported an under-voltage event to the system logs. Note that over-voltage events are not reported but often accompany under-voltage events and only the fuse remains in the way to prevent damage to the Raspberry Pi in the extreme case (the fuse does not protect if you are powering the Raspberry Pi via GPIO). Cheap power supplies, when unable to provide enough power, tend to spike voltage too high in response to the situation. Problems caused by insufficient or unstable power supply are very difficult to diagnose. Most likely, your USB grabber will fail first, but this is not always the case: Raspberry Pi modules, such as the embedded USB controller or network card, may also stop working properly.</li> <li>USB grabber performance: FPS and average time to decode a frame. You also usually want the FPS to be as high as possible with the lowest resolution possible at the same time. There are settings in the USB grabber configuration that can help reduce the resolution if the grabber doesn't have a hardware scaler. Keep decoding time below 20ms.</li> <li>Each user configured light source is listed here. Each instance takes input from e.g. your USB grabber or flatbuffer source and forwards it further: directly to the LED device if smoothing is off or to the smoothing sampler unit otherwise.</li> <li>If smoothing processing is enabled, it can increase or decrease the frame rate of the stream delivered by the instance. The result is then routed to the final LED device driver.</li> <li>Light source/LED strip driver. Here you have information on how many frames were received directly from the smoothing unit or from the instance, and how many actually went to the device. Note that some protocols do not guarantee that the frames actually arrived on the device, e.g. UDP used by WLED or the Philips Hue Entertainment API (and no error will be detected or reported).</li> <li>If you have the 'Continuous output' option disabled, you may see dropped frames in the statistics (trash\u2011can icon). With this option off, HyperHDR saves resources by skipping RGB frame updates to the LED device more often than once per second if the frames are identical. Otherwise, these statistics may indicate that the LED rendering queue is becoming clogged.</li> </ol>"},{"location":"Raspberry-Pi-5-PWM.html","title":"Raspberry Pi 5 GPIO PWM \ud83c\udd95","text":"<p>The Raspberry Pi 5 can use its RP1/PIO controller to control Neopixel LEDs, such as WS2812B RGB or SK6812 RGBW, using GPIO. You should still use a 3.3V to 5V level shifter to be fully compliant with the specifications of these LEDs.</p> <p>1 Requires root! Works only for Raspberry Pi 5 or newer if equipped with RP1 controller. 2 Must define LED strip in the overlay first!    - For example: <code>echo \"dtoverlay=ws2812-pio,gpio=18,num_leds=30,rgbw\" | sudo tee -a /boot/firmware/config.txt</code>  or edit <code>/boot/firmware/config.txt</code> manually    - Adjust <code>num_leds</code>: total number of LEDs, must be configured the same in HyperHDR    - Adjust  <code>rgbw</code> only for sk6812 RGBW, otherwise remove it    - After editing /boot/firmware/config.txt restart is required    - If you configure everything correctly, you should see the /dev/leds0 device in dmesg log  </p> <p>Warning</p> <p>Requires fixed ws2812 PIO kernel module: https://github.com/raspberrypi/linux/issues/7108  As for 2025-10-29 you need to switch Trixie kernel to testing kernel version and reboot: <code>sudo rpi-update beb2783757e6aa6c4abe4187dc74da4ce2f451fc</code> It will be included in the next RPi OS release for kernel &gt; 6.12.55</p> <p>Testing setup: </p> <p> </p> <p>Results of testing using fixed kernel module:  </p>"},{"location":"Raspberry-Pi-OS-read-only-mode.html","title":"Raspberry Pi OS read-only mode","text":""},{"location":"Raspberry-Pi-OS-read-only-mode.html#make-your-raspberry-pi-system-read-only","title":"Make your Raspberry Pi system read-only","text":"<p>Raspberry Pi OS system has a very nice tool that you can use to enable/disable the read-only mode at will.</p> <p><code>sudo raspi-config</code></p> <p>It will protect your Raspberry Pi system from corruption if you don't have a dedicated &amp; safe powering off mechanism for the Rpi. And will extend the life of your SD card since all writes will be stored in the memory.</p> <p> </p> <p>Then restart the system. If you need to make some changes in configuration then disable the overlay (and restart the system), apply new configuration and enable the overlay again (and restart the system).  </p>"},{"location":"Software-screen-capture.html","title":"Software screen capture","text":""},{"location":"Software-screen-capture.html#topics","title":"Topics","text":"<ol> <li>Windows DirectX11 screen capture</li> <li>Linux Pipewire Portal screen capture for Wayland</li> </ol>"},{"location":"Software-screen-capture.html#windows-directx11-screen-capture","title":"Windows DirectX11 screen capture","text":"<p>The previous version of HyperHDR introduced screen capture on Windows systems, fully utilizing the hardware acceleration of the graphics card. Thanks to it, automatic color space conversion occurs there, but that's not all.</p> <p>Another problem is sending the captured image from the graphics card memory to the computer memory: we do not want to fill this bridge, which could have a negative impact on the use of the PC: for example, cause jerking in games. Here, pixer &amp; vertex shaders implemented in HyperHDR come to the rescue, which scale the bitmap already in the graphics card memory, which is the optimal solution.</p> <p>HyperHDR v21 brings another solution that may interest gamers equipped with multiple monitors: multi-monitor support. Simply select the multi-monitor option for a given graphics adapter and HyperHDR will capture the image from all monitors, later combining them into one. Full hardware acceleration is always working here, which will handle even situations when the monitors have different resolutions or, for example, one of them is SDR and the other is HDR.</p> <p>The DirectX grabber's performance is very good and allows you to save buying a USB grabber and HDMI splitter: everything is done in software. There is one case you need to remember though: it will not capture copy-protected streams such as commercial streaming services.</p>"},{"location":"Software-screen-capture.html#configuration-of-windows-directx11-screen-capture","title":"Configuration of Windows DirectX11 screen capture","text":"<p>Open the <code>Video capturing</code> tab and scroll down the page. Now if you want, you can select a video device from the list or enable multi-screen capture. Once you have finished configuring DirectX Grabber and saved it, set <code>enable system capture</code> and save the changes again.</p> <p></p> <p> </p> <p>Now you can open the video live preview window and verify if everything is OK. The example below shows an active multi-monitor configuration where the displays have different parameters.</p> <p> </p> <p> </p> <p>Just increase re-order mode till you get correct order for multi-display mode in the video live preview</p> <p></p>"},{"location":"Software-screen-capture.html#linux-pipewire-portal-screen-capture-for-wayland","title":"Linux Pipewire Portal screen capture for Wayland","text":""},{"location":"Software-screen-capture.html#1-run-as-application-not-daemon","title":"1. Run as Application (Not Daemon)","text":"<p>The PipeWire grabber will not work if HyperHDR is running as a system service (daemon). Due to Wayland security, the grabber must be launched as a user application within an active session to gain screen access.</p>"},{"location":"Software-screen-capture.html#2-hardware-acceleration-dmaegl","title":"2. Hardware Acceleration (DMA/EGL)","text":"<p>To use the high-performance DMA/EGL mode, vendor-specific drivers are required. Standard open-source drivers usually lack the necessary support for hardware buffer sharing.</p> <ul> <li>Intel: Requires <code>intel-media-va-driver-non-free</code> (the standard <code>intel-media-va-driver</code> is often insufficient for DMA).</li> <li>NVIDIA: Requires proprietary NVIDIA drivers (the <code>nouveau</code> driver most likely won't provide DMA mode in Pipewire).</li> </ul> <p>Note: If these drivers are missing, the system will use File Descriptor (SHM) mode. It remains functional, but lacks the full performance of zero-copy acceleration.</p>"},{"location":"Software-screen-capture.html#3-configuration-steps","title":"3. Configuration Steps","text":"<p>In the \"Software Screen Capture\" tab, ensure that Pipewire is listed as the automatically selected grabber. (Note: Pipewire will not be available if HyperHDR is running as a Linux system service). </p> <p>Under \"Instance Screen Capture\", check \"Enable system capture\". This should trigger a monitor selection window managed by Portal. If the window does not appear, you should analyze both the HyperHDR and system Portal logs to identify why the selection prompt is not being presented.</p> <p> </p>"},{"location":"Software-screen-capture.html#4-verification-and-stability","title":"4. Verification and Stability","text":"<p>Once successful, you can verify if the video stream is working correctly in the live preview. Check the HyperHDR logs for more detailed technical information, such as whether DMA mode was activated or if it fell back to file descriptors. Please note: HyperHDR only reports its capability to handle DMA mode; whether Pipewire actually provides it depends on your GFX driver, Pipewire version or the Wayland compositor rather than our application itself.</p> <p>We strongly recommend enabling the \"Disable on OS lock or monitor off\" option in the \"General\" tab. This minimizes the risk of the grabber attempting to resume before the user session or display are fully re-initialized. Such timing issues can cause Pipewire to reject the saved session token, forcing you to manually re-select the monitor.</p> <p> </p>"},{"location":"Zigbee2MQTT-lights.html","title":"Zigbee2MQTT lights","text":"<p>Caution</p> <p>Silicon Labs controllers (EFR32MG21, like ZBDongle-E) are not supported: they may or may not work. Sorry, they are too unstable in zigbee2mqtt for our purposes with touchlink not working in any modern firmware. The current status of this driver is experimental. It should be faster than integration via Home Assistant =&gt; Zigbee2MQTT. Zigbee2MQTT performance is limited for colors streaming despite our changes.</p>"},{"location":"Zigbee2MQTT-lights.html#1-installing--configuring-mosquitto-and-zigbee2mqtt","title":"1. Installing &amp; configuring Mosquitto and Zigbee2MQTT","text":"<p>Start HyperHDR, select the Adalight LED driver but do not save changes and expand the output port list. You should find your Zigbee coordinator. Note the path, in this example it is <code>/dev/ttyACM0</code>:</p> <p></p> <p>Install necessary components: <pre><code>sudo apt update &amp;&amp; sudo apt install -y curl\nsudo curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash -\nsudo apt install -y mosquitto nodejs git make g++ gcc libsystemd-dev\n</code></pre></p> <p>Caution</p> <p>You must install our Zigbee2MQTT fork which is optimized for sending frequent color refreshes.  </p> <p>The original Zigbee2MQTT will get clogged with message queue after a few seconds and the lamps will lag so currently it is not suitable for our purposes.</p> <p>Install our Zigbee2MQTT fork: <pre><code>sudo mkdir /opt/zigbee2mqtt\nsudo chown -R ${USER}: /opt/zigbee2mqtt\ngit clone --depth 1 https://github.com/awawa-dev/zigbee2mqtt.git /opt/zigbee2mqtt\ncd /opt/zigbee2mqtt &amp;&amp; npm i --package-lock-only &amp;&amp; npm ci &amp;&amp; npm run build\n</code></pre></p> <p>Mosquitto configuration example (replace user hyperhdr and password with your choice \u26a0\ufe0f): <pre><code>echo \"allow_anonymous false\" | sudo tee /etc/mosquitto/conf.d/default.conf\necho \"password_file /etc/mosquitto/passwd\" | sudo tee -a /etc/mosquitto/conf.d/default.conf\n# this will open mosquitto port for external connections\necho \"listener 1883\" | sudo tee -a /etc/mosquitto/conf.d/default.conf\necho \"hyperhdr:CHANGE_THIS_PASSWORD\" | sudo tee /etc/mosquitto/passwd\nsudo mosquitto_passwd -U /etc/mosquitto/passwd\nsudo systemctl restart mosquitto\n</code></pre></p> <p>Configure Zigbee2MQTT: <pre><code>cp /opt/zigbee2mqtt/data/configuration.example.yaml /opt/zigbee2mqtt/data/configuration.yaml\nnano /opt/zigbee2mqtt/data/configuration.yaml\n</code></pre></p> <p>Set up the MQTT user and password, and also set the serial port you discovered in the first step of the tutorial. I also added <code>frontend</code> at the end to have access to the Zigbee2MQTT configuration panel via a web browser</p> <pre><code># Home Assistant integration (MQTT discovery)\nhomeassistant: false\n\n# allow new devices to join\npermit_join: true\n\n# MQTT settings\nmqtt:\n  # MQTT base topic for zigbee2mqtt MQTT messages\n  base_topic: zigbee2mqtt\n  # MQTT server URL\n  server: 'mqtt://localhost'\n  # MQTT server authentication, uncomment if required:\n  user: hyperhdr\n  password: CHANGE_THIS_PASSWORD\n\n# Serial settings\nserial:\n  # Location of CC2531 USB sniffer\n  port: /dev/ttyACM0\n  # only for cc2531, cc2651p\n  adapter: zstack\n\n# Enable Web frontend\nfrontend: true\n</code></pre> <p>Run Zigbee2MQTT, you should have the interface available at port 8080. Terminate the program later (CTRL - C): <pre><code>cd /opt/zigbee2mqtt\nnpm start\n</code></pre></p> <p>If this works, you can create a Zigbee service using this instruction: https://www.zigbee2mqtt.io/guide/installation/01_linux.html#optional-running-as-a-daemon-with-systemctl</p> <p>Then you can start adding lamps using e.g. the <code>Touchlink</code> function via the Zigbee2MQTT web interface at port 8080. You must put the lamps really close (&lt;10cm) to the USB Zigbee stick. Otherwise <code>Touchlink</code> won't find them.</p>"},{"location":"Zigbee2MQTT-lights.html#2-configuring-hyperhdr-zigbee2mqtt-driver","title":"2. Configuring HyperHDR Zigbee2MQTT driver","text":"<p>Go to the Advanced tab and open the <code>Network Services</code> tab. Configure the MQTT service by entering the previously selected user and password. I entered <code>localhost</code> as the host because HyperHDR and MQTT broker are running on the same unit in this example. For security reasons, you can block access to the HyperHDR API via MQTT if you do not use it.  </p> <p>After saving the MQTT settings, check the HyperHDR logs. It should have a status of: connected, just like in the screenshot</p> <p></p> <p>Open the \"LED hardware\" tab. There, select the Zigbee2MQTT driver and run the wizard. HyperHDR should find the lamps you previously configured in Zigbee2MQTT.</p> <p></p> <p>Now select an area on the TV for each lamp. You can click identify if you don't know which lamp has what name. Save the configuration and that's it.</p> <p>Caution</p> <p>Setting dynamic brightness (constant brightness = 0) doubles the communication overhead. May affect latency.</p>"},{"location":"_Sidebar.html","title":"Sidebar","text":"<ul> <li>Getting started. Needed components</li> <li>Software installation<ul> <li>Windows</li> <li>LibreELEC</li> <li>Linux/Debian&amp;Ubuntu repository</li> <li>Linux/RaspberryPi SD card</li> <li>Linux/general</li> <li>macOS </li> </ul> </li> <li>Configurations<ul> <li>Quick start</li> <li>Video source LUT calibration</li> <li>P010 high quality video format</li> <li>Automatic tone mapping</li> <li>Software screen capture</li> <li>Audio-reactive lighting effects</li> <li>Raspberry Pi 5 GPIO PWM \ud83c\udd95</li> <li>Zigbee2MQTT lights</li> <li>Home Assistant lights</li> <li>JSON API</li> <li>Instance synchronization</li> <li>Hue gradient light strips</li> <li>HyperSerialPico and others</li> </ul> </li> <li>Infinite Color Engine \ud83c\udd95</li> <li>Compiling HyperHDR</li> <li>FAQ</li> <li>3.3V to 5V level shifter</li> <li>Raspberry Pi OS read-only mode</li> </ul>"}]}